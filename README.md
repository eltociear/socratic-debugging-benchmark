# Socratic Debugging Benchmark


The repository contains the Socratic debugging dataset and accompanies the paper "Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations"  to appear in proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Application at ACL 2023.

There are 3 subfolders:
* evaluation_dataset: Contains all the dialogues used for evaluations in the paper. This subfolder excludes any dialogues with analogies that were not used for evaluations.
* final_dataset: Contains all 86 dialogues curated for the dataset. This subfolder includes dialogues with analogy use.
* manual_evaluation_dialogues: Contains the dialogues used for manual evaluation of the dataset.

TODO:

- [ ] Add the code used for inference and evaluation.
- [ ] Add code for the annotation tool.
- [ ] Add citation information
- [ ] Add the paper link
- [ ] Add Socratic debugging image

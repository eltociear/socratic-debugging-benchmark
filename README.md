# Socratic Debugging Benchmark


The repository contains the Socratic debugging dataset and accompanies the paper "Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations" submitted to the 18th Workshop on Innovative Use of NLP for Building Educational Application at ACL 2023.

There are 3 subfolders:
* evaluation_dataset: Contains all the dialogues used for evaluations in the paper. This subfolder excludes any dialogues with analogies that were not used for evaluations.
* final_dataset: Contains all 86 dialogues curated for the dataset. This subfolder includes dialogues with analogy use.
* manual_evaluation_dialogues: Contains the dialogues used for manual evaluation of the dataset.

TODO:

- [ ] Add the code used for inference and evaluation.
